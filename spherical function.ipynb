{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy.spatial import distance,distance_matrix\n",
    "from operator import add\n",
    "from random import random\n",
    "from mip import Model, xsum, minimize, BINARY\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import math\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_selection import mutual_info_regression, f_classif,chi2,mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "h_limit=0.7\n",
    "r=4\n",
    "e=0.005\n",
    "\n",
    "\n",
    "####### START COUNTING\n",
    "\n",
    "start=time.process_time()\n",
    "\n",
    "##### function creating a list with number of elements defined by user ######\n",
    "def  list_creation(list_length):\n",
    "    list_name=[[]for i in range(len(list_length))]\n",
    "    return list_name\n",
    "\n",
    "##### function calculating distances between a center(certain point) and a list #####\n",
    "def distance_center(center,points,list_label):    \n",
    "    dist_b=list_creation(list_label)\n",
    "    j=0\n",
    "    for i in list_label:\n",
    "        dist_b[j]=distance.euclidean(center,points[i])\n",
    "        j=j+1\n",
    "    return dist_b\n",
    "\n",
    "\n",
    "##### function calculating distances between a center and a list\n",
    "##### and appending to list if value smaller than a min value \n",
    "def distance_cond_min(data_length,center,points,check_value,adding_list):\n",
    "    dist_r=list_creation(data_length)\n",
    "    j=0\n",
    "    for i in data_length:\n",
    "        dist_r[j]=distance.euclidean(center,points[i])\n",
    "        if dist_r[j]<check_value:\n",
    "            adding_list.append(i)\n",
    "        j=j+1\n",
    "            \n",
    "    return dist_r, adding_list\n",
    "\n",
    "##### function performing steps of STAGE 1 #######\n",
    "def stage_1(data1,data2,cluster,feature_list_1,feature_list_2):\n",
    "    p_list=[]\n",
    "    for s in range(len(data1)):\n",
    "        cluster[s][0]=feature_list_1[s]\n",
    "        dist_b=distance_center(cluster[s][0],feature_list_2,data2.index)\n",
    "        cluster[s][1]=min(dist_b)\n",
    "        dist_r,cluster[s][4]=distance_cond_min(data1.index,cluster[s][0],feature_list_1,cluster[s][1],cluster[s][4])\n",
    "\n",
    "        dist_r_filt=[]\n",
    "        for m in cluster[s][4]:\n",
    "            dist_r_filt.append(dist_r[m])\n",
    "\n",
    "        if len(cluster[s][4])>1:\n",
    "            cluster[s][2]=max(dist_r_filt)\n",
    "        else:\n",
    "            cluster[s][2]=cluster[s][1]/2\n",
    "\n",
    "        p_list.append(s)\n",
    "    \n",
    "    return cluster,p_list\n",
    "\n",
    "###### function for creating a cluster ######\n",
    "def cluster_creation(data_source):\n",
    "    cluster=list_creation(data_source)\n",
    "    for i in range(len(data_source)):\n",
    "        cluster[i]=[[],0,0,1,[],[]]\n",
    "    \n",
    "    return cluster\n",
    "\n",
    "###### function for creating J lists ######\n",
    "def j_creation(data_source):\n",
    "    j=list_creation(data_source)\n",
    "    for i in range(len(data_source)):\n",
    "        j[i]=[i]\n",
    "    \n",
    "    return j\n",
    "\n",
    "###### function that checks if item of a list A is not in list B and append the distance i to a new list\n",
    "def check_append(origin_list,check_list,dist_b,new_list):    \n",
    "    for i in origin_list.index:\n",
    "        if i not in check_list:\n",
    "            new_list.append(dist_b[i])\n",
    "    return new_list\n",
    "\n",
    "###### function for calculation of lamda\n",
    "def lamda_calc(x_u,x_w,d,center_new):\n",
    "    v1=[x1-x2 for (x1,x2) in zip([sum(x) for x in zip(x_u/2,x_w/2)],center_new)]\n",
    "    v2=[x1-x2 for (x1,x2) in zip(x_u,x_w)]\n",
    "    lamda=sum(p*q for p,q in zip(v1, v2))/sum(p*q for p,q in zip(d, v2))\n",
    "    return lamda\n",
    "\n",
    "###### fuction with basic cluster calculations\n",
    "def newcluster_calc(center_new,feature_1,feature_2,data1,data2,list_label):\n",
    "        \n",
    "    dist_r=distance_center(center_new,feature_1,list_label)\n",
    "    r_new=max(dist_r)  ####find new r\n",
    "       \n",
    "    m2_new=[]\n",
    "    dist_b,m2_new=distance_cond_min(data2.index,center_new,feature_2,r_new,m2_new) #### find new  m2\n",
    "    \n",
    "    new_dist=[]\n",
    "    new_dist=check_append(data2,m2_new,dist_b,new_dist)\n",
    "    if new_dist!=[]:\n",
    "        b_new=min(new_dist)\n",
    "    else: b_new=r_new*1.5                               ############################find new b\n",
    "\n",
    "    m1_new=[]\n",
    "    dist_b,m1_new=distance_cond_min(data1.index,center_new,feature_1,b_new,m1_new) #### find new  m1\n",
    "    h=len(m1_new)/(len(m1_new)+len(m2_new))   #define h\n",
    "    \n",
    "    return b_new,r_new,h,m1_new,m2_new\n",
    "\n",
    "####### function calculating position of max or min value (input 1 for min, 0 for max )\n",
    "def dist_position(center_new,points,data_source,func):\n",
    "                    \n",
    "    dist=distance_center(center_new,points,data_source)\n",
    "    if func==1:                        \n",
    "        w_pos=np.where(dist==np.amin(dist))\n",
    "        p=data_source[w_pos[-1][0]]\n",
    "    #elif func==1:\n",
    "    else:\n",
    "        w_pos=np.where(dist==np.amax(dist))\n",
    "        p=data_source[w_pos[0][0]]\n",
    "    return p\n",
    "\n",
    "def angle(v1, v2):\n",
    "    return math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "######## function calculating stage 2\n",
    "def stage_2_calc(data1,data2,C,C_op,s_coord1,s_coord2,P):\n",
    "\n",
    "    C_stage2=np.zeros(shape=(len(data1),6),dtype=list)\n",
    "\n",
    "    nonsingleton_s=[]\n",
    "    for i in range(len(data1)):\n",
    "        if len(C[i][4])>1:\n",
    "            nonsingleton_s.append(i)\n",
    "\n",
    "    for s in nonsingleton_s:\n",
    "        add=[]\n",
    "        for fe in range(len(C[s][0])):\n",
    "            add.append(0)\n",
    "\n",
    "        center_new=[]\n",
    "        for fe in range(len(C[s][0])):\n",
    "            for i in C[s][4]:\n",
    "                add[fe]=add[fe]+(C[i][0][fe])\n",
    "            center_new.append(add[fe]/len(C[s][4]))    ####### find new center\n",
    "        \n",
    "        b_new,r_new,h,m1_new,m2_new=newcluster_calc(center_new,s_coord1,s_coord2,data1,data2,C[s][4])\n",
    "        \n",
    "        if len(m2_new)!=0:           \n",
    "            counter=0\n",
    "            while h<1 and counter<10:\n",
    "                ### finding new center based on (11)-(13)\n",
    "                d=[[]for fe in range(len(C[s][0]))]\n",
    "                for fe in range(len(C[s][0])):\n",
    "                    d[fe]=s_coord1[s][fe]-center_new[fe]\n",
    "                u=dist_position(center_new,s_coord1,m1_new,0)\n",
    "                \n",
    "                avail=[]\n",
    "                for sa in m2_new:\n",
    "                    d_w=list_creation(C[s][0])\n",
    "                    for fe in range(len(C[s][0])):\n",
    "                        d_w[fe]=C_op[sa][0][fe]-center_new[fe]\n",
    "                    \n",
    "                    if np.dot(d,d_w)/norm(d)/norm(d_w)<=0:\n",
    "                        avail.append(sa)\n",
    "                \n",
    "                if avail==[]:\n",
    "                    avail=m2_new\n",
    "                \n",
    "                \n",
    "                dist=distance_center(center_new,s_coord2,avail)\n",
    "                w_pos=np.where(dist==np.amin(dist))\n",
    "                w=avail[w_pos[-1][0]]\n",
    "                \n",
    "                ###########\n",
    "                #lamda and new center calculation based on equation (12) and (13)\n",
    "                lamda=lamda_calc(C[u][0],C_op[w][0],d,center_new)\n",
    "                center_new=[sum(x) for x in zip([(lamda+e)*(x1-x2) for (x1,x2) in zip(C[s][0],center_new)],center_new)]\n",
    "\n",
    "                if np.isnan(center_new).any():\n",
    "                    center_new=[]\n",
    "                    for fe in range(len(C[s][0])):\n",
    "                        for i in C[s][4]:\n",
    "                            add[fe]=add[fe]+(C[i][0][fe])\n",
    "                        center_new.append(add[fe]/len(C[s][4]))\n",
    "                    \n",
    "                    \n",
    "                #### find new r,M2 and b\n",
    "    \n",
    "                b_new,r_new,h,m1_new,m2_new=newcluster_calc(center_new,s_coord1,s_coord2,data1,data2,m1_new)\n",
    "                counter=counter+1\n",
    "\n",
    "            if len(set(m1_new)-set(C[s][4]))!=0:   ###check if M1 has changed to update r again\n",
    "                dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                r_new=max(dist_r)\n",
    "                \n",
    "\n",
    "        for (fe,i) in zip([center_new,b_new,r_new,len(m1_new)/(len(m1_new)+len(m2_new)),m1_new,m2_new],range(6)):\n",
    "            C_stage2[s][i]=fe    \n",
    "\n",
    "    for s in P:\n",
    "        if s not in nonsingleton_s:\n",
    "            for fe in range(6):\n",
    "                C_stage2[s][fe]=C[s][fe] \n",
    "\n",
    "    return C_stage2,P\n",
    "\n",
    "\n",
    "####### random list generator\n",
    "def gam_generator(r):\n",
    "    gam=[[]for i in range(r)]\n",
    "                #### generate a(i)\n",
    "    for i in range(r):\n",
    "        gam[i]=random()\n",
    "    gam=gam+[1]\n",
    "    gam.sort()\n",
    "    return gam\n",
    "\n",
    "######### finding the center of a cluster based on the coordinates of the included samples\n",
    "def center_add(s,coord,length):\n",
    "    add=[]\n",
    "    for fe in range(len(coord[s])):\n",
    "        add.append(0)\n",
    "    center_new=[]\n",
    "    for fe in range(len(coord[s])):\n",
    "        for i in length:\n",
    "            add[fe]=add[fe]+coord[i][fe]\n",
    "        center_new.append(add[fe]/len(length))\n",
    "    return center_new\n",
    "\n",
    "####### stage 3 calculation function\n",
    "def stage_3_func(data1,data2,C_stage2,C_op_stage2,s_coord1,s_coord2):\n",
    "    C_stage3=np.zeros(shape=(len(C_stage2),6),dtype=list)\n",
    "    gam=gam_generator(r)\n",
    "\n",
    "    for s in data1.index:\n",
    "        for fe in range(6):\n",
    "            C_stage3[s][fe]=C_stage2[s][fe]\n",
    "        counter=0    \n",
    "        alpha=1\n",
    "        expansion=False\n",
    "        for g in gam :\n",
    "            b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "            m1_new=[s]\n",
    "            dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "            center_new=center_add(s,s_coord1,m1_new)                                \n",
    "\n",
    "            dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "            r_new=max(dist_r)\n",
    "\n",
    "            m2_new=[]\n",
    "            dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "            if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                \n",
    "                new_dist=[]\n",
    "                new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                if new_dist!=[]:\n",
    "                    b_new=min(new_dist)\n",
    "                else:\n",
    "                    b_new=2*r_new\n",
    "\n",
    "                m1_new=[s]\n",
    "                dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                    C_stage3[s][i]=fe\n",
    "                expansion=True\n",
    "                break\n",
    "\n",
    "        if expansion==True:\n",
    "\n",
    "            while expansion==True and counter<10:\n",
    "                counter=counter+1\n",
    "                expansion=False\n",
    "                for g in gam:\n",
    "                    b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "                    m1_new=[s]\n",
    "                    dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "                    center_new=center_add(s,s_coord1,m1_new)    \n",
    "\n",
    "                    dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                    r_new=max(dist_r)\n",
    "\n",
    "                    m2_new=[]\n",
    "                    dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "                    if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                        \n",
    "                        new_dist=[]\n",
    "                        new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                        if new_dist!=[]:\n",
    "                            b_new=min(new_dist)\n",
    "                        else:\n",
    "                            b_new=2*r_new\n",
    "\n",
    "                        m1_new=[s]\n",
    "                        dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                        h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                        for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            C_stage3[s][i]=fe\n",
    "                        expansion=True\n",
    "\n",
    "        if expansion==False:\n",
    "            expansion=True\n",
    "            while expansion==True and counter<10:\n",
    "                counter=counter+1\n",
    "                alpha=alpha/2\n",
    "                expansion=False\n",
    "                for g in gam :\n",
    "                    b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "                    m1_new=[s]\n",
    "                    dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "                    center_new=center_add(s,s_coord1,m1_new)   \n",
    "\n",
    "                    dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                    r_new=max(dist_r)\n",
    "\n",
    "                    m2_new=[]\n",
    "                    dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "\n",
    "                    if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                        \n",
    "                        new_dist=[]\n",
    "                        new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                        if new_dist!=[]:\n",
    "                            b_new=min(new_dist)\n",
    "                        else:\n",
    "                            b_new=2*r_new\n",
    "\n",
    "                        m1_new=[s]\n",
    "                        dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                        h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                        for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            C_stage3[s][i]=fe\n",
    "                        expansion=True         \n",
    "    return C_stage3\n",
    "\n",
    "######## Singleton Treatment Stage Calculations\n",
    "def singleton_calc(data,data_op,cluster, cluster_op,s_coord,s_coord_op,J,P):\n",
    "    \n",
    "    for s in data.index:\n",
    "        if len(cluster[s][4])==1:\n",
    "            if len(J[s])>=2:\n",
    "                P[s]='deleted'\n",
    "             \n",
    "            else:\n",
    "                dist_k=[1e5 for i in range(len(data))]\n",
    "                for i in data.index:\n",
    "                    if i!=s:\n",
    "                        dist_k[i]=distance.euclidean(s_coord[s],s_coord[i])\n",
    "                        \n",
    "                u=np.argmin(dist_k)\n",
    "                center_new=[(x_u+x_i)/2 for (x_i,x_u) in zip(s_coord[s],s_coord[u])]\n",
    "                dist_r=distance_center(center_new,s_coord,data.index)\n",
    "                r_new=min(dist_r)\n",
    "\n",
    "                m2_new=[]\n",
    "                dist_b,m2_new=distance_cond_min(data_op.index,center_new,s_coord_op,r_new,m2_new)\n",
    "\n",
    "                new_dist=[]\n",
    "                new_dist=check_append(data_op,m2_new,dist_b,new_dist)\n",
    "                b_new=min(new_dist)\n",
    "\n",
    "                m1_new=[s]\n",
    "                dist_b,m1_new=distance_cond_min(data.index,center_new,s_coord,b_new,m1_new)\n",
    "                \n",
    "                h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "                \n",
    "                if h_new>=h_limit:\n",
    "                    for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            cluster[s][i]=fe\n",
    "                else:\n",
    "                    P[s]='deleted'\n",
    "                                   \n",
    "    return pd.DataFrame(cluster),P\n",
    "                    \n",
    "\n",
    "\n",
    "####### calculation of the necessary weights for stage5\n",
    "def weight_calc(cluster,data,P):\n",
    "    weight=np.zeros(shape=(len(cluster),1)) #########\n",
    "    i=0\n",
    "    for s in P:\n",
    "        weight[s]=cluster[s][2]/len(cluster[s][4])/cluster[s][3]\n",
    "        i=i+1\n",
    "    return weight\n",
    "\n",
    "####### calculating the factor matrix for linear optimization\n",
    "def matrix_calc(cluster, P,data):\n",
    "    matrix=np.zeros(shape=(len(P),len(cluster)))##########\n",
    "    \n",
    "    for c in range(len(cluster)):\n",
    "        for s,i in zip(P,range(len(P))):\n",
    "            if s in cluster[c][4]:\n",
    "                \n",
    "                matrix[i][c]=1\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "# finding the index of the samples that belong only in one cluster\n",
    "#in order to addd constraint to retain that cluster so that the sample is not lost\n",
    "def single_sample_count(data,P,cluster):\n",
    "    counter=[0 for i in range(len(data))]\n",
    "    ind=[]\n",
    "    for s in P:\n",
    "        counter[s]=0\n",
    "        for c in P:\n",
    "            if s in cluster.transpose()[4][c]:\n",
    "                counter[s]=counter[s]+1\n",
    "    if counter.count(1)>0:\n",
    "        ind=counter.index(1)\n",
    "        \n",
    "    return counter,ind\n",
    "\n",
    "###### finding the L and C lists for point classification\n",
    "def cluster_find(new_point,cluster):\n",
    "    dist,l,c=([],[],[])\n",
    "    for cl in range(len(cluster)):\n",
    "        dist.append(distance.euclidean(new_point,cluster.values[cl][0]))\n",
    "        if dist[cl]<cluster.values[cl][1]:\n",
    "            l.append(cluster.index[cl])\n",
    "        if dist[cl]<cluster.values[cl][2]:\n",
    "            c.append(cluster.index[cl])\n",
    "    return l,c\n",
    "\n",
    "###### calculating the sum for case 2 of new point classification\n",
    "def sum_calc(w,new_point,cluster,l,c):\n",
    "    sum_1=sum(w[s]*(distance.euclidean(new_point,cluster.values[j][0])-cluster.values[j][2]) \n",
    "            for s,j in zip(cluster.index,range(len(cluster))))\n",
    "    temp_list=[] \n",
    "    for s in l:\n",
    "        if s not in c:\n",
    "            temp_list.append(s)\n",
    "    sum_2=sum(w[s]*(distance.euclidean(new_point,cluster.values[j][0])-cluster.values[j][1]) \n",
    "            for s,j in zip(temp_list,range(len(temp_list))))\n",
    "    if sum_1!=0 and sum_2!=0:\n",
    "        s_1=1/sum_1+1/sum_2\n",
    "    elif sum_1==0:\n",
    "        s_1=1/sum_2\n",
    "    else:\n",
    "        s_1=1/sum_1\n",
    "    return s_1\n",
    "\n",
    "def kenStone(X, Y, train_ratio):\n",
    "    k = round(train_ratio*len(X))\n",
    "    originalX = X\n",
    "\n",
    "    train_idx = list()\n",
    "\n",
    "    distA = pd.DataFrame(distance_matrix(X, X), index=X.index, columns=X.index)\n",
    "    obj1, obj2 = distA.stack().index[np.argmax(distA.values)]\n",
    "    train_idx.append(obj1)  # add 1st object to list\n",
    "    train_idx.append(obj2)  # add 2nd object to list\n",
    "    X = X.drop(obj1) # remove 1st object from initial dataset\n",
    "    X = X.drop(obj2) # remove 2nd object from initial dataset\n",
    "\n",
    "    for i in range(0, k-2):\n",
    "        distB = pd.DataFrame(distance_matrix(X, pd.DataFrame(originalX.loc[train_idx,:])), index=X.index, columns=train_idx)\n",
    "        closer = list() #pd.DataFrame([pd.DataFrame([min(distB.iloc[0,])])])\n",
    "\n",
    "        for j in range(0, len(X)):\n",
    "            closer.append(min(distB.iloc[j,])) #(pd.DataFrame([min(distB.iloc[j,])]))\n",
    "\n",
    "        obj = X.index[closer.index(max(closer))]\n",
    "        train_idx.append(obj)\n",
    "        X = X.drop(obj)\n",
    "\n",
    "    trainX = originalX.loc[train_idx,]\n",
    "    trainY = Y.loc[train_idx,]\n",
    "\n",
    "    test_idx = X.index\n",
    "    testX = originalX.loc[test_idx,]\n",
    "    testY = Y.loc[test_idx,]\n",
    "\n",
    "    return trainX, testX, trainY, testY\n",
    "\n",
    "def cluster_selection(cluster,w,mat,ind,P,J,solver_name): \n",
    "    C=range(len(cluster))#####\n",
    "    C_single=range(len(cluster)) ######\n",
    "    m=Model(solver_name=solver_name)\n",
    "\n",
    "    y=[m.add_var(var_type=BINARY) for c in C]\n",
    "    y_single=[m.add_var(var_type=BINARY) for c_single in C_single]\n",
    "    \n",
    "    ###objective function\n",
    "    m.objective = minimize(xsum(w[c][0] * y[c] for c in C))\n",
    "\n",
    "    #####add constraints\n",
    "    for con in range(len(mat.transpose())):\n",
    "        m.add_constr(xsum(mat.transpose()[con][c] * y[c] for c in C) >= 1) \n",
    "    for c_single in C_single:\n",
    "        m.add_constr(y_single[c_single] >=1)\n",
    "    if ind!=[]:\n",
    "        for j in [ind]:\n",
    "            m.add_constr(y[j]==y_single[j])\n",
    "    for s in P:\n",
    "        \n",
    "        m.add_constr(xsum(y[c] for c in J[s])>=1)\n",
    "\n",
    "    m.optimize()\n",
    "    y = [y[c].x for c in C]\n",
    "    return m.objective_value, y,m.status\n",
    "\n",
    "def cluster_filtering(cluster,y):\n",
    "    cluster_f=pd.DataFrame(cluster)\n",
    "    cluster_f['label']=y\n",
    "    cluster_f=cluster_f[cluster_f['label']==1]\n",
    "    return cluster_f\n",
    "\n",
    "def j_calculation(data,P,cluster):\n",
    "    \n",
    "    J=list_creation(data)\n",
    "    for s in data.index:\n",
    "        for sa in P:\n",
    "            if s in cluster[sa][4]:\n",
    "                J[s].append(sa)\n",
    "    return J\n",
    "\n",
    "def j_calculation2(data,P,cluster):\n",
    "    \n",
    "    J=list_creation(data)\n",
    "    for s in data.index:  \n",
    "        for sa in P:    \n",
    "            if s in cluster[4][sa]: ################\n",
    "                J[s].append(sa)\n",
    "    return J\n",
    "\n",
    "def print_stats(y_t, y_pred):\n",
    "    conf_mat=confusion_matrix(y_t.values, y_pred)\n",
    "    total=sum(sum(conf_mat))\n",
    "    accuracy=(conf_mat[0,0]+conf_mat[1,1])/total\n",
    "    print ('Accuracy : ', accuracy)\n",
    "    sensitivity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "    print('Sensitivity : ', sensitivity )\n",
    "    specificity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "    print('Specificity : ', specificity)\n",
    "    mat_coef = matthews_corrcoef(y_t, y_pred)\n",
    "    print('MAtthews coeef : ', mat_coef)\n",
    "    print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stages(data_1,data_2,solver_name,X_test,pred):\n",
    "## create clusters\n",
    "    C_1=cluster_creation(data_1)\n",
    "    C_2=cluster_creation(data_2)\n",
    "\n",
    "    #####create arrays for the coordinates/features\n",
    "    s_coord_1=list_creation(data_1)\n",
    "    for s in range(len(data_1)):\n",
    "        s_coord_1[s]=data_1.values[s]\n",
    "\n",
    "    s_coord_2=list_creation(data_2)\n",
    "    for s in range(len(data_2)):\n",
    "        s_coord_2[s]=data_2.values[s]    \n",
    "\n",
    "    C_1,P_1=stage_1(data_1,data_2,C_1,s_coord_1,s_coord_2)\n",
    "    C_2,P_2=stage_1(data_2,data_1,C_2,s_coord_2,s_coord_1)\n",
    "\n",
    "    C_1_stage2,P_1=stage_2_calc(data_1,data_2,C_1,C_2,s_coord_1,s_coord_2,P_1)\n",
    "    C_2_stage2,P_2=stage_2_calc(data_2,data_1,C_2,C_1,s_coord_2,s_coord_1,P_2)\n",
    "\n",
    "    C_1_stage3=stage_3_func(data_1,data_2,C_1_stage2,C_2_stage2,s_coord_1,s_coord_2)\n",
    "    C_2_stage3=stage_3_func(data_2,data_1,C_2_stage2,C_1_stage2,s_coord_2,s_coord_1)\n",
    "\n",
    "    J_1=j_calculation(data_1,P_1,C_1_stage3)\n",
    "    J_2=j_calculation(data_2,P_2,C_2_stage3)\n",
    "\n",
    "    C_1_stage4=np.zeros(shape=(len(C_1),6),dtype=list)\n",
    "    C_2_stage4=np.zeros(shape=(len(C_2),6),dtype=list)\n",
    "    for sa in data_1.index:\n",
    "        for fe in range(6):      \n",
    "            C_1_stage4[sa][fe]=C_1_stage3[sa][fe]\n",
    "    for sa in data_2.index:\n",
    "        for fe in range(6):      \n",
    "            C_2_stage4[sa][fe]=C_2_stage3[sa][fe] \n",
    "\n",
    "    C_1_stage4,P_1=singleton_calc(data_1,data_2,C_1_stage3,C_2_stage3,s_coord_1,s_coord_2,J_1,P_1)\n",
    "    C_2_stage4,P_2=singleton_calc(data_2,data_1,C_2_stage3,C_1_stage3,s_coord_2,s_coord_1,J_2,P_2)\n",
    "\n",
    "    while 'deleted' in P_1:\n",
    "        P_1.remove('deleted')\n",
    "\n",
    "    while 'deleted' in P_2:\n",
    "        P_2.remove('deleted')\n",
    "\n",
    "    J_1=j_calculation2(data_1,P_1,C_1_stage4)\n",
    "    J_2=j_calculation2(data_2,P_2,C_2_stage4)\n",
    "\n",
    "    C_1_stage4=C_1_stage4.values\n",
    "    C_2_stage4=C_2_stage4.values\n",
    "\n",
    "    w_1=weight_calc(C_1_stage4,data_1,P_1)\n",
    "    w_2=weight_calc(C_2_stage4,data_2,P_2)\n",
    "\n",
    "    mat_1=matrix_calc(C_1_stage4,data_1.index,P_1)\n",
    "    mat_2=matrix_calc(C_2_stage4,data_2.index,P_2)\n",
    "\n",
    "    counter_1,ind_1=single_sample_count(data_1,P_1,C_1_stage4)\n",
    "    counter_2,ind_2=single_sample_count(data_2,P_2,C_2_stage4)\n",
    "\n",
    "    val_1,y_1,hi=cluster_selection(C_1_stage4,w_1,mat_1,ind_1,P_1,J_1,solver_name)\n",
    "    val_2,y_2,hi2=cluster_selection(C_2_stage4,w_2,mat_2,ind_2,P_2,J_2,solver_name)\n",
    "\n",
    "    cluster_1=cluster_filtering(C_1_stage4,y_1).drop('label',axis=1)\n",
    "    cluster_2=cluster_filtering(C_2_stage4,y_2).drop('label',axis=1)\n",
    "\n",
    "    l_1=list_creation(X_test)\n",
    "    c_1=list_creation(X_test)\n",
    "    l_2=list_creation(X_test)\n",
    "    c_2=list_creation(X_test)\n",
    "    \n",
    "    y_pred=[]  \n",
    "    if 1 in pred:\n",
    "        \n",
    "        for s,i in zip(X_test.values,range(len(X_test))):\n",
    "            l_1,c_1=cluster_find(s,cluster_1)\n",
    "            l_2,c_2=cluster_find(s,cluster_2)   \n",
    "\n",
    "            if bool(l_1==[]) ^ bool(l_2==[]):\n",
    "                if l_1==[]:\n",
    "                    y_pred.append(2)###### add new observation to the '2' classification\n",
    "                else:\n",
    "                    y_pred.append(1)###### add new observation to the '1' classification\n",
    "            elif l_1!=[] and l_2!=[]:\n",
    "                if bool(c_1==[]) ^ bool(c_2==[]):\n",
    "                    if c_1==[]:\n",
    "                        y_pred.append(2) ###### add new observation to the '2' classification\n",
    "                    else:\n",
    "                        y_pred.append(1) ###### add new observation to the '1' classification\n",
    "                else:\n",
    "                    s_1=sum_calc(w_1,s,cluster_1,l_1,c_1)\n",
    "                    s_2=sum_calc(w_2,s,cluster_2,l_2,c_2)\n",
    "                    if s_1>=s_2:\n",
    "                        y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                    else:\n",
    "                        y_pred.append(2) ######## add new observation to the '2' classification\n",
    "            else:\n",
    "                d_1=[(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]) for j in range(len(cluster_1))]\n",
    "                d_2=[(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]) for j in range(len(cluster_2))]\n",
    "                d_sum=d_1+d_2\n",
    "                d_sum.sort()\n",
    "                if d_sum[0] in d_1:\n",
    "                    if d_sum[1] in d_1 :\n",
    "                        y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                    else:\n",
    "                        s_1=[1/(w_1[c]*(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]))\n",
    "                             for c,j in zip(cluster_1.index,range(len(cluster_1)))][d_1.index(d_sum[0])]\n",
    "\n",
    "                        s_2=[1/(w_2[c]*(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]))\n",
    "                            for c,j in zip(cluster_2.index,range(len(cluster_2)))][d_2.index(d_sum[1])]\n",
    "                        if s_1>s_2:\n",
    "                            y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                        else:\n",
    "                            y_pred.append(2) ######## add new observation to the '2' classification\n",
    "\n",
    "                if d_sum[0] in d_2:\n",
    "                    if d_sum[1] in d_2:\n",
    "                        pass ######## add new observation to the '2' classification\n",
    "                    else:\n",
    "                        s_1=[1/(w_1[c]*(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]))\n",
    "                             for c,j in zip(cluster_1.index,range(len(cluster_1)))][d_2.index(d_sum[0])]\n",
    "\n",
    "                        s_2=[1/(w_2[c]*(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]))\n",
    "                            for c,j in zip(cluster_2.index,range(len(cluster_2)))][d_1.index(d_sum[1])]\n",
    "                        if s_2>s_1:\n",
    "                            y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                        else:\n",
    "                            y_pred.append(2)######## add new observation to the '2' classification\n",
    "    \n",
    "    y_pred_1=[]\n",
    "    if 2 in pred:\n",
    "        for s in X_test.index:\n",
    "            dist_1=min([distance.euclidean(X_test.loc[s],cluster_1[0].values[c]) for c in range(len(cluster_1))])\n",
    "            dist_2=min([distance.euclidean(X_test.loc[s],cluster_2[0].values[c]) for c in range(len(cluster_2))])\n",
    "            if dist_1<dist_2:\n",
    "                y_pred_1.append(1)\n",
    "            else:\n",
    "                y_pred_1.append(2)\n",
    "                \n",
    "    y_pred_2=[]\n",
    "    if 3 in pred:\n",
    "        for s in X_test.index:\n",
    "            dist_1=sum([1/(1+distance.euclidean(X_test.loc[s],cluster_1[0].values[c])) for c in range(len(cluster_1))])/len(cluster_1)\n",
    "            dist_2=sum([1/(1+distance.euclidean(X_test.loc[s],cluster_2[0].values[c])) for c in range(len(cluster_2))])/len(cluster_2)\n",
    "            if dist_1<dist_2:\n",
    "                y_pred_2.append(2)\n",
    "            else:\n",
    "                y_pred_2.append(1)\n",
    "\n",
    "    y_p=[[] for i in range(3)]\n",
    "    y_p[0]=y_pred\n",
    "    y_p[1]=y_pred_1\n",
    "    y_p[2]=y_pred_2\n",
    "    \n",
    "    y_pr=[ele for ele in y_p if ele != []]       \n",
    "    return y_pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    " def spherical(data_file,\n",
    "               endpoint_col,\n",
    "               t_ratio=0.7,\n",
    "               feat_sel=False,\n",
    "               print_report=True,\n",
    "               solver_name='cbc',\n",
    "               pred=[1,2,3],\n",
    "               feat_num=5,\n",
    "               feat_func=chi2):\n",
    "        \n",
    "    data = pd.read_csv(data_file, header=0, sep=\",\", encoding= 'cp1252')\n",
    "    data.columns=range(len(data.columns))\n",
    "    X=pd.DataFrame(data).drop([0],axis=1)     \n",
    "\n",
    "    X_scaled = (X - X.min()) / (X.max() - X.min())\n",
    "    X_train, X_test, y_train,y_test =kenStone(X_scaled.drop(endpoint_col,axis=1), X[endpoint_col], t_ratio)\n",
    "\n",
    "    if feat_sel==True:\n",
    "        model=SelectKBest(feat_func, k=feat_num).fit(X_train,y_train)\n",
    "        X_new=pd.DataFrame(model.transform(X_train))\n",
    "        X_new['Toxicity']=data[endpoint_col]\n",
    "        X_train=X_new\n",
    "\n",
    "        data_1=X_train[X_train['Toxicity']==1].drop(['Toxicity'],axis=1)\n",
    "        data_2=X_train[X_train['Toxicity']==2].drop(['Toxicity'],axis=1)\n",
    "        data_1.index=range(len(data_1))\n",
    "        data_2.index=range(len(data_2))\n",
    "\n",
    "        X_test=model.transform(X_test)\n",
    "        X_test=pd.DataFrame(X_test)\n",
    "        X_test.index=range(len(X_test))\n",
    "    else:\n",
    "        X_train[endpoint_col]=data[endpoint_col]\n",
    "        data_1=X_train[X_train[endpoint_col]==1].drop([endpoint_col],axis=1)\n",
    "        data_2=X_train[X_train[endpoint_col]==2].drop([endpoint_col],axis=1)\n",
    "        data_1.index=range(len(data_1))\n",
    "        data_2.index=range(len(data_2))\n",
    "        X_test.index=range(len(X_test))\n",
    "    \n",
    "    y_pred=stages(data_1,data_2,solver_name,X_test,pred)\n",
    "    \n",
    "    if print_report==True:\n",
    "        for i in range(len(pred)):\n",
    "            print('Statistical performance for method:',pred[i])\n",
    "            print_stats(y_test,y_pred[i])\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = #\"C:/Users... dataset file directory\n",
    "y_predicted=spherical(data_file,\n",
    "                      endpoint_col=1,\n",
    "                      t_ratio=0.75,\n",
    "                      feat_sel=False,\n",
    "                      feat_num=4,\n",
    "                      feat_func=chi2,\n",
    "                      print_report=False,\n",
    "                      solver_name='grb', \n",
    "                      pred=[1,2,3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
