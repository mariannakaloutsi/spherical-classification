{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from scipy.spatial import distance,distance_matrix\n",
    "from operator import add\n",
    "from random import random\n",
    "from mip import Model, xsum, minimize, BINARY\n",
    "from sklearn.metrics import confusion_matrix,classification_report\n",
    "import math\n",
    "from numpy.linalg import norm\n",
    "from sklearn.feature_selection import mutual_info_regression, f_classif,chi2,mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.decomposition import PCA\n",
    "h_limit=0.7\n",
    "r=4\n",
    "e=0.005\n",
    "\n",
    "\n",
    "####### START COUNTING\n",
    "\n",
    "start=time.process_time()\n",
    "\n",
    "##### function creating a list with number of elements defined by user ######\n",
    "def  list_creation(list_length):\n",
    "    list_name=[[]for i in range(len(list_length))]\n",
    "    return list_name\n",
    "\n",
    "##### function calculating distances between a center(certain point) and a list #####\n",
    "def distance_center(center,points,list_label):    \n",
    "    dist_b=list_creation(list_label)\n",
    "    j=0\n",
    "    for i in list_label:\n",
    "        dist_b[j]=distance.euclidean(center,points[i])\n",
    "        j=j+1\n",
    "    return dist_b\n",
    "\n",
    "\n",
    "##### function calculating distances between a center and a list\n",
    "##### and appending to list if value smaller than a min value \n",
    "def distance_cond_min(data_length,center,points,check_value,adding_list):\n",
    "    dist_r=list_creation(data_length)\n",
    "    j=0\n",
    "    for i in data_length:\n",
    "        dist_r[j]=distance.euclidean(center,points[i])\n",
    "        if dist_r[j]<check_value:\n",
    "            adding_list.append(i)\n",
    "        j=j+1\n",
    "            \n",
    "    return dist_r, adding_list\n",
    "\n",
    "##### function performing steps of STAGE 1 #######\n",
    "def stage_1(data1,data2,cluster,feature_list_1,feature_list_2):\n",
    "    p_list=[]\n",
    "    for s in range(len(data1)):\n",
    "        cluster[s][0]=feature_list_1[s]\n",
    "        dist_b=distance_center(cluster[s][0],feature_list_2,data2.index)\n",
    "        cluster[s][1]=min(dist_b)\n",
    "        dist_r,cluster[s][4]=distance_cond_min(data1.index,cluster[s][0],feature_list_1,cluster[s][1],cluster[s][4])\n",
    "\n",
    "        dist_r_filt=[]\n",
    "        for m in cluster[s][4]:\n",
    "            dist_r_filt.append(dist_r[m])\n",
    "\n",
    "        if len(cluster[s][4])>1:\n",
    "            cluster[s][2]=max(dist_r_filt)\n",
    "        else:\n",
    "            cluster[s][2]=cluster[s][1]/2\n",
    "\n",
    "        p_list.append(s)\n",
    "    \n",
    "    return cluster,p_list\n",
    "\n",
    "###### function for creating a cluster ######\n",
    "def cluster_creation(data_source):\n",
    "    cluster=list_creation(data_source)\n",
    "    for i in range(len(data_source)):\n",
    "        cluster[i]=[[],0,0,1,[],[]]\n",
    "    \n",
    "    return cluster\n",
    "\n",
    "###### function for creating J lists ######\n",
    "def j_creation(data_source):\n",
    "    j=list_creation(data_source)\n",
    "    for i in range(len(data_source)):\n",
    "        j[i]=[i]\n",
    "    \n",
    "    return j\n",
    "\n",
    "###### function that checks if item of a list A is not in list B and append the distance i to a new list\n",
    "def check_append(origin_list,check_list,dist_b,new_list):    \n",
    "    for i in origin_list.index:\n",
    "        if i not in check_list:\n",
    "            new_list.append(dist_b[i])\n",
    "    return new_list\n",
    "\n",
    "###### function for calculation of lamda\n",
    "def lamda_calc(x_u,x_w,d,center_new):\n",
    "    v1=[x1-x2 for (x1,x2) in zip([sum(x) for x in zip(x_u/2,x_w/2)],center_new)]\n",
    "    v2=[x1-x2 for (x1,x2) in zip(x_u,x_w)]\n",
    "    lamda=sum(p*q for p,q in zip(v1, v2))/sum(p*q for p,q in zip(d, v2))\n",
    "    return lamda\n",
    "\n",
    "###### fuction with basic cluster calculations\n",
    "def newcluster_calc(center_new,feature_1,feature_2,data1,data2,list_label):\n",
    "        \n",
    "    dist_r=distance_center(center_new,feature_1,list_label)\n",
    "    r_new=max(dist_r)  ####find new r\n",
    "       \n",
    "    m2_new=[]\n",
    "    dist_b,m2_new=distance_cond_min(data2.index,center_new,feature_2,r_new,m2_new) #### find new  m2\n",
    "    \n",
    "    new_dist=[]\n",
    "    new_dist=check_append(data2,m2_new,dist_b,new_dist)\n",
    "    if new_dist!=[]:\n",
    "        b_new=min(new_dist)\n",
    "    else: b_new=r_new*1.5                               ############################find new b\n",
    "\n",
    "    m1_new=[]\n",
    "    dist_b,m1_new=distance_cond_min(data1.index,center_new,feature_1,b_new,m1_new) #### find new  m1\n",
    "    h=len(m1_new)/(len(m1_new)+len(m2_new))   #define h\n",
    "    \n",
    "    return b_new,r_new,h,m1_new,m2_new\n",
    "\n",
    "####### function calculating position of max or min value (input 1 for min, 0 for max )\n",
    "def dist_position(center_new,points,data_source,func):\n",
    "                    \n",
    "    dist=distance_center(center_new,points,data_source)\n",
    "    if func==1:                        \n",
    "        w_pos=np.where(dist==np.amin(dist))\n",
    "        p=data_source[w_pos[-1][0]]\n",
    "    #elif func==1:\n",
    "    else:\n",
    "        w_pos=np.where(dist==np.amax(dist))\n",
    "        p=data_source[w_pos[0][0]]\n",
    "    return p\n",
    "\n",
    "def angle(v1, v2):\n",
    "    return math.acos(dotproduct(v1, v2) / (length(v1) * length(v2)))\n",
    "\n",
    "######## function calculating stage 2\n",
    "def stage_2_calc(data1,data2,C,C_op,s_coord1,s_coord2,P):\n",
    "\n",
    "    C_stage2=np.zeros(shape=(len(data1),6),dtype=list)\n",
    "\n",
    "    nonsingleton_s=[]\n",
    "    for i in range(len(data1)):\n",
    "        if len(C[i][4])>1:\n",
    "            nonsingleton_s.append(i)\n",
    "\n",
    "    for s in nonsingleton_s:\n",
    "        add=[]\n",
    "        for fe in range(len(C[s][0])):\n",
    "            add.append(0)\n",
    "\n",
    "        center_new=[]\n",
    "        for fe in range(len(C[s][0])):\n",
    "            for i in C[s][4]:\n",
    "                add[fe]=add[fe]+(C[i][0][fe])\n",
    "            center_new.append(add[fe]/len(C[s][4]))    ####### find new center\n",
    "        \n",
    "        b_new,r_new,h,m1_new,m2_new=newcluster_calc(center_new,s_coord1,s_coord2,data1,data2,C[s][4])\n",
    "        \n",
    "        if len(m2_new)!=0:           \n",
    "            counter=0\n",
    "            while h<1 and counter<10:\n",
    "                ### finding new center based on (11)-(13)\n",
    "                d=[[]for fe in range(len(C[s][0]))]\n",
    "                for fe in range(len(C[s][0])):\n",
    "                    d[fe]=s_coord1[s][fe]-center_new[fe]\n",
    "                u=dist_position(center_new,s_coord1,m1_new,0)\n",
    "                \n",
    "                avail=[]\n",
    "                for sa in m2_new:\n",
    "                    d_w=list_creation(C[s][0])\n",
    "                    for fe in range(len(C[s][0])):\n",
    "                        d_w[fe]=C_op[sa][0][fe]-center_new[fe]\n",
    "                    \n",
    "                    if np.dot(d,d_w)/norm(d)/norm(d_w)<=0:\n",
    "                        avail.append(sa)\n",
    "                \n",
    "                if avail==[]:\n",
    "                    avail=m2_new\n",
    "                \n",
    "                \n",
    "                dist=distance_center(center_new,s_coord2,avail)\n",
    "                w_pos=np.where(dist==np.amin(dist))\n",
    "                w=avail[w_pos[-1][0]]\n",
    "                \n",
    "                ###########\n",
    "                #lamda and new center calculation based on equation (12) and (13)\n",
    "                lamda=lamda_calc(C[u][0],C_op[w][0],d,center_new)\n",
    "                center_new=[sum(x) for x in zip([(lamda+e)*(x1-x2) for (x1,x2) in zip(C[s][0],center_new)],center_new)]\n",
    "\n",
    "                if np.isnan(center_new).any():\n",
    "                    center_new=[]\n",
    "                    for fe in range(len(C[s][0])):\n",
    "                        for i in C[s][4]:\n",
    "                            add[fe]=add[fe]+(C[i][0][fe])\n",
    "                        center_new.append(add[fe]/len(C[s][4]))\n",
    "                    \n",
    "                    \n",
    "                #### find new r,M2 and b\n",
    "    \n",
    "                b_new,r_new,h,m1_new,m2_new=newcluster_calc(center_new,s_coord1,s_coord2,data1,data2,m1_new)\n",
    "                counter=counter+1\n",
    "\n",
    "            if len(set(m1_new)-set(C[s][4]))!=0:   ###check if M1 has changed to update r again\n",
    "                dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                r_new=max(dist_r)\n",
    "                \n",
    "\n",
    "        for (fe,i) in zip([center_new,b_new,r_new,len(m1_new)/(len(m1_new)+len(m2_new)),m1_new,m2_new],range(6)):\n",
    "            C_stage2[s][i]=fe    \n",
    "\n",
    "    for s in P:\n",
    "        if s not in nonsingleton_s:\n",
    "            for fe in range(6):\n",
    "                C_stage2[s][fe]=C[s][fe] \n",
    "\n",
    "    return C_stage2,P\n",
    "\n",
    "\n",
    "####### random list generator\n",
    "def gam_generator(r):\n",
    "    gam=[[]for i in range(r)]\n",
    "                #### generate a(i)\n",
    "    for i in range(r):\n",
    "        gam[i]=random()\n",
    "    gam=gam+[1]\n",
    "    gam.sort()\n",
    "    return gam\n",
    "\n",
    "######### finding the center of a cluster based on the coordinates of the included samples\n",
    "def center_add(s,coord,length):\n",
    "    add=[]\n",
    "    for fe in range(len(coord[s])):\n",
    "        add.append(0)\n",
    "    center_new=[]\n",
    "    for fe in range(len(coord[s])):\n",
    "        for i in length:\n",
    "            add[fe]=add[fe]+coord[i][fe]\n",
    "        center_new.append(add[fe]/len(length))\n",
    "    return center_new\n",
    "\n",
    "####### stage 3 calculation function\n",
    "def stage_3_func(data1,data2,C_stage2,C_op_stage2,s_coord1,s_coord2):\n",
    "    C_stage3=np.zeros(shape=(len(C_stage2),6),dtype=list)\n",
    "    gam=gam_generator(r)\n",
    "\n",
    "    for s in data1.index:\n",
    "        for fe in range(6):\n",
    "            C_stage3[s][fe]=C_stage2[s][fe]\n",
    "        counter=0    \n",
    "        alpha=1\n",
    "        expansion=False\n",
    "        for g in gam :\n",
    "            b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "            m1_new=[s]\n",
    "            dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "            center_new=center_add(s,s_coord1,m1_new)                                \n",
    "\n",
    "            dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "            r_new=max(dist_r)\n",
    "\n",
    "            m2_new=[]\n",
    "            dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "            if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                \n",
    "                new_dist=[]\n",
    "                new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                if new_dist!=[]:\n",
    "                    b_new=min(new_dist)\n",
    "                else:\n",
    "                    b_new=2*r_new\n",
    "\n",
    "                m1_new=[s]\n",
    "                dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                    C_stage3[s][i]=fe\n",
    "                expansion=True\n",
    "                break\n",
    "\n",
    "        if expansion==True:\n",
    "\n",
    "            while expansion==True and counter<10:\n",
    "                counter=counter+1\n",
    "                expansion=False\n",
    "                for g in gam:\n",
    "                    b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "                    m1_new=[s]\n",
    "                    dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "                    center_new=center_add(s,s_coord1,m1_new)    \n",
    "\n",
    "                    dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                    r_new=max(dist_r)\n",
    "\n",
    "                    m2_new=[]\n",
    "                    dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "                    if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                        \n",
    "                        new_dist=[]\n",
    "                        new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                        if new_dist!=[]:\n",
    "                            b_new=min(new_dist)\n",
    "                        else:\n",
    "                            b_new=2*r_new\n",
    "\n",
    "                        m1_new=[s]\n",
    "                        dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                        h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                        for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            C_stage3[s][i]=fe\n",
    "                        expansion=True\n",
    "\n",
    "        if expansion==False:\n",
    "            expansion=True\n",
    "            while expansion==True and counter<10:\n",
    "                counter=counter+1\n",
    "                alpha=alpha/2\n",
    "                expansion=False\n",
    "                for g in gam :\n",
    "                    b_new=(1+alpha*g)*C_stage3[s][1]\n",
    "\n",
    "                    m1_new=[s]\n",
    "                    dist_b,m1_new=distance_cond_min(data1.index,C_stage3[s][0],s_coord1,b_new,m1_new)\n",
    "                    center_new=center_add(s,s_coord1,m1_new)   \n",
    "\n",
    "                    dist_r=distance_center(center_new,s_coord1,m1_new)\n",
    "                    r_new=max(dist_r)\n",
    "\n",
    "                    m2_new=[]\n",
    "                    dist_b,m2_new=distance_cond_min(data2.index,center_new,s_coord2,r_new,m2_new)\n",
    "\n",
    "\n",
    "                    if len(m1_new)/(len(m1_new)+len(m2_new))> h_limit and len(m1_new)>len(C_stage3[s][4]):\n",
    "                        \n",
    "                        new_dist=[]\n",
    "                        new_dist=check_append(data2,m2_new,dist_b,new_dist)    \n",
    "                        if new_dist!=[]:\n",
    "                            b_new=min(new_dist)\n",
    "                        else:\n",
    "                            b_new=2*r_new\n",
    "\n",
    "                        m1_new=[s]\n",
    "                        dist_b,m1_new=distance_cond_min(data1.index,center_new,s_coord1,b_new,m1_new)\n",
    "                        h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "\n",
    "                        for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            C_stage3[s][i]=fe\n",
    "                        expansion=True         \n",
    "    return C_stage3\n",
    "\n",
    "######## Singleton Treatment Stage Calculations\n",
    "def singleton_calc(data,data_op,cluster, cluster_op,s_coord,s_coord_op,J,P):\n",
    "    \n",
    "    for s in data.index:\n",
    "        if len(cluster[s][4])==1:\n",
    "            if len(J[s])>=2:\n",
    "                P[s]='deleted'\n",
    "             \n",
    "            else:\n",
    "                dist_k=[1e5 for i in range(len(data))]\n",
    "                for i in data.index:\n",
    "                    if i!=s:\n",
    "                        dist_k[i]=distance.euclidean(s_coord[s],s_coord[i])\n",
    "                        \n",
    "                u=np.argmin(dist_k)\n",
    "                center_new=[(x_u+x_i)/2 for (x_i,x_u) in zip(s_coord[s],s_coord[u])]\n",
    "                dist_r=distance_center(center_new,s_coord,data.index)\n",
    "                r_new=min(dist_r)\n",
    "\n",
    "                m2_new=[]\n",
    "                dist_b,m2_new=distance_cond_min(data_op.index,center_new,s_coord_op,r_new,m2_new)\n",
    "\n",
    "                new_dist=[]\n",
    "                new_dist=check_append(data_op,m2_new,dist_b,new_dist)\n",
    "                b_new=min(new_dist)\n",
    "\n",
    "                m1_new=[s]\n",
    "                dist_b,m1_new=distance_cond_min(data.index,center_new,s_coord,b_new,m1_new)\n",
    "                \n",
    "                h_new=len(m1_new)/(len(m1_new)+len(m2_new))\n",
    "                \n",
    "                if h_new>=h_limit:\n",
    "                    for i,fe in zip(range(6),[center_new,b_new,r_new,h_new,m1_new,m2_new]):\n",
    "                            cluster[s][i]=fe\n",
    "                else:\n",
    "                    P[s]='deleted'\n",
    "                                   \n",
    "    return pd.DataFrame(cluster),P\n",
    "                    \n",
    "\n",
    "\n",
    "####### calculation of the necessary weights for stage5\n",
    "def weight_calc(cluster,data,P):\n",
    "    weight=np.zeros(shape=(len(cluster),1)) #########\n",
    "    i=0\n",
    "    for s in P:\n",
    "        weight[s]=cluster[s][2]/len(cluster[s][4])/cluster[s][3]\n",
    "        i=i+1\n",
    "    return weight\n",
    "\n",
    "####### calculating the factor matrix for linear optimization\n",
    "def matrix_calc(cluster, P,data):\n",
    "    matrix=np.zeros(shape=(len(P),len(cluster)))##########\n",
    "    \n",
    "    for c in range(len(cluster)):\n",
    "        for s,i in zip(P,range(len(P))):\n",
    "            if s in cluster[c][4]:\n",
    "                \n",
    "                matrix[i][c]=1\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "# finding the index of the samples that belong only in one cluster\n",
    "#in order to addd constraint to retain that cluster so that the sample is not lost\n",
    "def single_sample_count(data,P,cluster):\n",
    "    counter=[0 for i in range(len(data))]\n",
    "    ind=[]\n",
    "    for s in P:\n",
    "        counter[s]=0\n",
    "        for c in P:\n",
    "            if s in cluster.transpose()[4][c]:\n",
    "                counter[s]=counter[s]+1\n",
    "    if counter.count(1)>0:\n",
    "        ind=counter.index(1)\n",
    "        \n",
    "    return counter,ind\n",
    "\n",
    "###### finding the L and C lists for point classification\n",
    "def cluster_find(new_point,cluster):\n",
    "    dist,l,c=([],[],[])\n",
    "    for cl in range(len(cluster)):\n",
    "        dist.append(distance.euclidean(new_point,cluster.values[cl][0]))\n",
    "        if dist[cl]<cluster.values[cl][1]:\n",
    "            l.append(cluster.index[cl])\n",
    "        if dist[cl]<cluster.values[cl][2]:\n",
    "            c.append(cluster.index[cl])\n",
    "    return l,c\n",
    "\n",
    "###### calculating the sum for case 2 of new point classification\n",
    "def sum_calc(w,new_point,cluster,l,c):\n",
    "    sum_1=sum(w[s]*(distance.euclidean(new_point,cluster.values[j][0])-cluster.values[j][2]) \n",
    "            for s,j in zip(cluster.index,range(len(cluster))))\n",
    "    temp_list=[] \n",
    "    for s in l:\n",
    "        if s not in c:\n",
    "            temp_list.append(s)\n",
    "    sum_2=sum(w[s]*(distance.euclidean(new_point,cluster.values[j][0])-cluster.values[j][1]) \n",
    "            for s,j in zip(temp_list,range(len(temp_list))))\n",
    "    if sum_1!=0 and sum_2!=0:\n",
    "        s_1=1/sum_1+1/sum_2\n",
    "    elif sum_1==0:\n",
    "        s_1=1/sum_2\n",
    "    else:\n",
    "        s_1=1/sum_1\n",
    "    return s_1\n",
    "\n",
    "def kenStone(X, Y, train_ratio):\n",
    "    k = round(train_ratio*len(X))\n",
    "    originalX = X\n",
    "\n",
    "    train_idx = list()\n",
    "\n",
    "    distA = pd.DataFrame(distance_matrix(X, X), index=X.index, columns=X.index)\n",
    "    obj1, obj2 = distA.stack().index[np.argmax(distA.values)]\n",
    "    train_idx.append(obj1)  # add 1st object to list\n",
    "    train_idx.append(obj2)  # add 2nd object to list\n",
    "    X = X.drop(obj1) # remove 1st object from initial dataset\n",
    "    X = X.drop(obj2) # remove 2nd object from initial dataset\n",
    "\n",
    "    for i in range(0, k-2):\n",
    "        distB = pd.DataFrame(distance_matrix(X, pd.DataFrame(originalX.loc[train_idx,:])), index=X.index, columns=train_idx)\n",
    "        closer = list() #pd.DataFrame([pd.DataFrame([min(distB.iloc[0,])])])\n",
    "\n",
    "        for j in range(0, len(X)):\n",
    "            closer.append(min(distB.iloc[j,])) #(pd.DataFrame([min(distB.iloc[j,])]))\n",
    "\n",
    "        obj = X.index[closer.index(max(closer))]\n",
    "        train_idx.append(obj)\n",
    "        X = X.drop(obj)\n",
    "\n",
    "    trainX = originalX.loc[train_idx,]\n",
    "    trainY = Y.loc[train_idx,]\n",
    "\n",
    "    test_idx = X.index\n",
    "    testX = originalX.loc[test_idx,]\n",
    "    testY = Y.loc[test_idx,]\n",
    "\n",
    "    return trainX, testX, trainY, testY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## importing and preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create clusters\n",
    "C_1=cluster_creation(data_1)\n",
    "C_2=cluster_creation(data_2)\n",
    "\n",
    "#####create arrays for the coordinates/features\n",
    "s_coord_1=list_creation(data_1)\n",
    "for s in range(len(data_1)):\n",
    "    s_coord_1[s]=data_1.values[s]\n",
    "\n",
    "s_coord_2=list_creation(data_2)\n",
    "for s in range(len(data_2)):\n",
    "    s_coord_2[s]=data_2.values[s]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1,P_1=stage_1(data_1,data_2,C_1,s_coord_1,s_coord_2)\n",
    "C_2,P_2=stage_1(data_2,data_1,C_2,s_coord_2,s_coord_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "C_1_stage2,P_1=stage_2_calc(data_1,data_2,C_1,C_2,s_coord_1,s_coord_2,P_1)\n",
    "C_2_stage2,P_2=stage_2_calc(data_2,data_1,C_2,C_1,s_coord_2,s_coord_1,P_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n"
     ]
    }
   ],
   "source": [
    "C_1_stage3=stage_3_func(data_1,data_2,C_1_stage2,C_2_stage2,s_coord_1,s_coord_2)\n",
    "C_2_stage3=stage_3_func(data_2,data_1,C_2_stage2,C_1_stage2,s_coord_2,s_coord_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_calculation(data,P,cluster):\n",
    "    \n",
    "    J=list_creation(data)\n",
    "    for s in data.index:\n",
    "        for sa in P:\n",
    "            if s in cluster[sa][4]:\n",
    "                J[s].append(sa)\n",
    "    return J\n",
    "\n",
    "J_1=j_calculation(data_1,P_1,C_1_stage3)\n",
    "J_2=j_calculation(data_2,P_2,C_2_stage3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1_stage4=np.zeros(shape=(len(C_1),6),dtype=list)\n",
    "C_2_stage4=np.zeros(shape=(len(C_2),6),dtype=list)\n",
    "for sa in data_1.index:\n",
    "    for fe in range(6):      \n",
    "        \n",
    "        C_1_stage4[sa][fe]=C_1_stage3[sa][fe]\n",
    "for sa in data_2.index:\n",
    "    for fe in range(6):      \n",
    "        C_2_stage4[sa][fe]=C_2_stage3[sa][fe]     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1_stage4,P_1=singleton_calc(data_1,data_2,C_1_stage3,C_2_stage3,s_coord_1,s_coord_2,J_1,P_1)\n",
    "C_2_stage4,P_2=singleton_calc(data_2,data_1,C_2_stage3,C_1_stage3,s_coord_2,s_coord_1,J_2,P_2)\n",
    "\n",
    "while 'deleted' in P_1:\n",
    "    P_1.remove('deleted')\n",
    "    \n",
    "while 'deleted' in P_2:\n",
    "    P_2.remove('deleted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def j_calculation2(data,P,cluster):\n",
    "    \n",
    "    J=list_creation(data)\n",
    "    for s in data.index:  \n",
    "        for sa in P:    \n",
    "            if s in cluster[4][sa]: ################\n",
    "                J[s].append(sa)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "J_1=j_calculation2(data_1,P_1,C_1_stage4)\n",
    "J_2=j_calculation2(data_2,P_2,C_2_stage4)\n",
    "\n",
    "C_1_stage4=C_1_stage4.values\n",
    "C_2_stage4=C_2_stage4.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_1=weight_calc(C_1_stage4,data_1,P_1)\n",
    "w_2=weight_calc(C_2_stage4,data_2,P_2)\n",
    "\n",
    "mat_1=matrix_calc(C_1_stage4,data_1.index,P_1)\n",
    "mat_2=matrix_calc(C_2_stage4,data_2.index,P_2)\n",
    "\n",
    "counter_1,ind_1=single_sample_count(data_1,P_1,C_1_stage4)\n",
    "counter_2,ind_2=single_sample_count(data_2,P_2,C_2_stage4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_selection(cluster,w,mat,ind,P,J): \n",
    "    C=range(len(cluster))#####\n",
    "    C_single=range(len(cluster)) ######\n",
    "    m=Model(solver_name='grb')\n",
    "\n",
    "    y=[m.add_var(var_type=BINARY) for c in C]\n",
    "    y_single=[m.add_var(var_type=BINARY) for c_single in C_single]\n",
    "    \n",
    "    ###objective function\n",
    "    m.objective = minimize(xsum(w[c][0] * y[c] for c in C))\n",
    "\n",
    "    #####add constraints\n",
    "    for con in range(len(mat.transpose())):\n",
    "        m.add_constr(xsum(mat.transpose()[con][c] * y[c] for c in C) >= 1) \n",
    "    for c_single in C_single:\n",
    "        m.add_constr(y_single[c_single] >=1)\n",
    "    if ind!=[]:\n",
    "        for j in [ind]:\n",
    "            m.add_constr(y[j]==y_single[j])\n",
    "    for s in P:\n",
    "        m.add_constr(xsum(y[c] for c in J[s])>=1)\n",
    "\n",
    "    m.optimize()\n",
    "    y = [y[c].x for c in C]\n",
    "    return m.objective_value, y,m.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_1,y_1,hi=cluster_selection(C_1_stage4,w_1,mat_1,ind_1,P_1,J_1)\n",
    "val_2,y_2,hi2=cluster_selection(C_2_stage4,w_2,mat_2,ind_2,P_2,J_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_filtering(cluster,y):\n",
    "    cluster_f=pd.DataFrame(cluster)\n",
    "    cluster_f['label']=y\n",
    "    cluster_f=cluster_f[cluster_f['label']==1]\n",
    "    return cluster_f\n",
    "\n",
    "cluster_1=cluster_filtering(C_1_stage4,y_1).drop('label',axis=1)\n",
    "cluster_2=cluster_filtering(C_2_stage4,y_2).drop('label',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_1=list_creation(X_test)\n",
    "c_1=list_creation(X_test)\n",
    "l_2=list_creation(X_test)\n",
    "c_2=list_creation(X_test)\n",
    "for s,i in zip(X_test.values,range(len(X_test))):\n",
    "    l_1[i],c_1[i]=cluster_find(s,cluster_1)\n",
    "    l_2[i],c_2[i]=cluster_find(s,cluster_2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=[]\n",
    "for s,i in zip(X_test.values,range(len(X_test))):\n",
    "    l_1,c_1=cluster_find(s,cluster_1)\n",
    "    l_2,c_2=cluster_find(s,cluster_2)   \n",
    "\n",
    "    if bool(l_1==[]) ^ bool(l_2==[]):\n",
    "        if l_1==[]:\n",
    "            y_pred.append(2)###### add new observation to the '2' classification\n",
    "        else:\n",
    "            y_pred.append(1)###### add new observation to the '1' classification\n",
    "    elif l_1!=[] and l_2!=[]:\n",
    "        if bool(c_1==[]) ^ bool(c_2==[]):\n",
    "            if c_1==[]:\n",
    "                y_pred.append(2) ###### add new observation to the '2' classification\n",
    "            else:\n",
    "                y_pred.append(1) ###### add new observation to the '1' classification\n",
    "        else:\n",
    "            s_1=sum_calc(w_1,s,cluster_1,l_1,c_1)\n",
    "            s_2=sum_calc(w_2,s,cluster_2,l_2,c_2)\n",
    "            if s_1>=s_2:\n",
    "                y_pred.append(1) ######## add new observation to the '1' classification\n",
    "            else:\n",
    "                y_pred.append(2) ######## add new observation to the '2' classification\n",
    "    else:\n",
    "        d_1=[(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]) for j in range(len(cluster_1))]\n",
    "        d_2=[(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]) for j in range(len(cluster_2))]\n",
    "        d_sum=d_1+d_2\n",
    "        d_sum.sort()\n",
    "        if d_sum[0] in d_1:\n",
    "            if d_sum[1] in d_1 :\n",
    "                y_pred.append(1) ######## add new observation to the '1' classification\n",
    "            else:\n",
    "                s_1=[1/(w_1[c]*(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]))\n",
    "                     for c,j in zip(cluster_1.index,range(len(cluster_1)))][d_1.index(d_sum[0])]\n",
    "\n",
    "                s_2=[1/(w_2[c]*(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]))\n",
    "                    for c,j in zip(cluster_2.index,range(len(cluster_2)))][d_2.index(d_sum[1])]\n",
    "                if s_1>s_2:\n",
    "                    y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                else:\n",
    "                    y_pred.append(2) ######## add new observation to the '2' classification\n",
    "\n",
    "        if d_sum[0] in d_2:\n",
    "            if d_sum[1] in d_2:\n",
    "                pass ######## add new observation to the '2' classification\n",
    "            else:\n",
    "                s_1=[1/(w_1[c]*(distance.euclidean(s,cluster_1.values[j][0])-cluster_1.values[j][2]))\n",
    "                     for c,j in zip(cluster_1.index,range(len(cluster_1)))][d_2.index(d_sum[0])]\n",
    "\n",
    "                s_2=[1/(w_2[c]*(distance.euclidean(s,cluster_2.values[j][0])-cluster_2.values[j][2]))\n",
    "                    for c,j in zip(cluster_2.index,range(len(cluster_2)))][d_1.index(d_sum[1])]\n",
    "                if s_2>s_1:\n",
    "                    y_pred.append(1) ######## add new observation to the '1' classification\n",
    "                else:\n",
    "                    y_pred.append(2)######## add new observation to the '2' classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALTERNATIVE CLASSIFICATION 1                    \n",
    "y_pred_1=[]\n",
    "for s in X_test.index:\n",
    "    dist_1=min([distance.euclidean(X_test.loc[s],cluster_1[0].values[c]) for c in range(len(cluster_1))])\n",
    "    dist_2=min([distance.euclidean(X_test.loc[s],cluster_2[0].values[c]) for c in range(len(cluster_2))])\n",
    "    if dist_1<dist_2:\n",
    "        y_pred_1.append(1)\n",
    "    else:\n",
    "        y_pred_1.append(2)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALTERNATIVE CLASSIFICATION 2\n",
    "y_pred_2=[]\n",
    "for s in X_test.index:\n",
    "    dist_1=sum([1/(1+distance.euclidean(X_test.loc[s],cluster_1[0].values[c])) for c in range(len(cluster_1))])/len(cluster_1)\n",
    "    dist_2=sum([1/(1+distance.euclidean(X_test.loc[s],cluster_2[0].values[c])) for c in range(len(cluster_2))])/len(cluster_2)\n",
    "    if dist_1<dist_2:\n",
    "        y_pred_2.append(2)\n",
    "    else:\n",
    "        y_pred_2.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00        14\n",
      "         2.0       0.91      1.00      0.95       135\n",
      "\n",
      "    accuracy                           0.91       149\n",
      "   macro avg       0.45      0.50      0.48       149\n",
      "weighted avg       0.82      0.91      0.86       149\n",
      "\n",
      "Accuracy :  0.9060402684563759\n",
      "Sensitivity :  0.0\n",
      "Specificity :  1.0\n",
      "MAtthews coeef :  0.0\n",
      "[[  0  14]\n",
      " [  0 135]]\n",
      "Execution time: 208.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\maria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\maria\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:846: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  mcc = cov_ytyp / np.sqrt(cov_ytyt * cov_ypyp)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "conf_mat=confusion_matrix(y_test, y_pred)\n",
    "total=sum(sum(conf_mat))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy=(conf_mat[0,0]+conf_mat[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "sensitivity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "specificity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "print('Specificity : ', specificity)\n",
    "mat_coef = matthews_corrcoef(y_test, y_pred)\n",
    "print('MAtthews coeef : ', mat_coef)\n",
    "print(conf_mat)\n",
    "\n",
    "#end=time.time()\n",
    "end=time.process_time()\n",
    "print('Execution time:',(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.36      0.36      0.36        14\n",
      "         2.0       0.93      0.93      0.93       135\n",
      "\n",
      "    accuracy                           0.88       149\n",
      "   macro avg       0.65      0.65      0.65       149\n",
      "weighted avg       0.88      0.88      0.88       149\n",
      "\n",
      "Accuracy :  0.8791946308724832\n",
      "Sensitivity :  0.35714285714285715\n",
      "Specificity :  0.9333333333333333\n",
      "MAtthews coeef :  0.2904761904761905\n",
      "[[  5   9]\n",
      " [  9 126]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_1))\n",
    "conf_mat=confusion_matrix(y_test, y_pred_1)\n",
    "total=sum(sum(conf_mat))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy=(conf_mat[0,0]+conf_mat[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "sensitivity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "specificity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "print('Specificity : ', specificity)\n",
    "mat_coef = matthews_corrcoef(y_test, y_pred_1)\n",
    "print('MAtthews coeef : ', mat_coef)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.26      0.71      0.38        14\n",
      "         2.0       0.96      0.79      0.87       135\n",
      "\n",
      "    accuracy                           0.79       149\n",
      "   macro avg       0.61      0.75      0.63       149\n",
      "weighted avg       0.90      0.79      0.82       149\n",
      "\n",
      "Accuracy :  0.785234899328859\n",
      "Sensitivity :  0.7142857142857143\n",
      "Specificity :  0.7925925925925926\n",
      "MAtthews coeef :  0.33929801531002013\n",
      "[[ 10   4]\n",
      " [ 28 107]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred_2))\n",
    "conf_mat=confusion_matrix(y_test, y_pred_2)\n",
    "total=sum(sum(conf_mat))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy=(conf_mat[0,0]+conf_mat[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "sensitivity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "specificity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "print('Specificity : ', specificity)\n",
    "mat_coef = matthews_corrcoef(y_test, y_pred_2)\n",
    "print('MAtthews coeef : ', mat_coef)\n",
    "print(conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_fa=[]\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i]+y_pred_1[i]+y_pred_2[i]>=5:\n",
    "        y_fa.append(2)\n",
    "    else:\n",
    "        y_fa.append(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.87248322147651\n",
      "Sensitivity :  0.2857142857142857\n",
      "Specificity :  0.9333333333333333\n",
      "MAtthews coeef :  0.22647919291236576\n",
      "[[  4  10]\n",
      " [  9 126]]\n"
     ]
    }
   ],
   "source": [
    "conf_mat=confusion_matrix(y_test, y_fa)\n",
    "total=sum(sum(conf_mat))\n",
    "#####from confusion matrix calculate accuracy\n",
    "accuracy=(conf_mat[0,0]+conf_mat[1,1])/total\n",
    "print ('Accuracy : ', accuracy)\n",
    "sensitivity = conf_mat[0,0]/(conf_mat[0,0]+conf_mat[0,1])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "specificity = conf_mat[1,1]/(conf_mat[1,0]+conf_mat[1,1])\n",
    "print('Specificity : ', specificity)\n",
    "mat_coef = matthews_corrcoef(y_test, y_fa)\n",
    "print('MAtthews coeef : ', mat_coef)\n",
    "print(conf_mat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
